{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "normalizer = WordNetLemmatizer()\n",
    "\n",
    "def get_part_of_speech(word):\n",
    "  probable_part_of_speech = wordnet.synsets(word)\n",
    "  pos_counts = Counter()\n",
    "  pos_counts[\"n\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"n\"]  )\n",
    "  pos_counts[\"v\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"v\"]  )\n",
    "  pos_counts[\"a\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"a\"]  )\n",
    "  pos_counts[\"r\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"r\"]  )\n",
    "  most_likely_part_of_speech = pos_counts.most_common(1)[0][0]\n",
    "  return most_likely_part_of_speech\n",
    "\n",
    "def preprocess_text(text):\n",
    "  cleaned = re.sub(r'\\W+', ' ', text).lower()\n",
    "  tokenized = word_tokenize(cleaned)\n",
    "  normalized = \" \".join([normalizer.lemmatize(token, get_part_of_speech(token)) for token in tokenized])\n",
    "  return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('news_set1.csv',encoding='latin-1')\n",
    "user_df = pd.read_csv('user_read_set1.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['Date'] =  pd.to_datetime(news_df['Date'].str.strip(), format='%m/%d/%Y')\n",
    "user_df['Date'] =  pd.to_datetime(user_df['Date'].str.strip(), format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df_temp = news_df.Heading.apply(preprocess_text)\n",
    "news_df['Article'] = news_df.Article.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_temp = news_df.Heading.apply(preprocess_text)\n",
    "user_df['Article'] = news_df.Article.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tf-idf model for news headline and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_onehot_encoded = OneHotEncoder().fit_transform(np.array(news_df[\"NewsType\"]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_headline_vectorizer = TfidfVectorizer(min_df = 0)\n",
    "tfidf_headline_features = tfidf_headline_vectorizer.fit_transform(news_df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Queried article details ==============================\n",
      "headline :  Stokes batters South Africa in blistering double \n",
      "Categoty :  sports\n",
      "Day and month :  2016-01-03 00:00:00\n",
      "\n",
      " ========================= Recommended articles :  =======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>Cosine Distance with the queried article</th>\n",
       "      <th>Category based Cosine Distance</th>\n",
       "      <th>Categoty</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Kiwis beat Pakistan to bag series 2 0</td>\n",
       "      <td>0.933562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sports</td>\n",
       "      <td>2016-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Watson to lead Australia for final India T20</td>\n",
       "      <td>0.944474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sports</td>\n",
       "      <td>2016-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>NZ Cricket apologises to Amir for a tau</td>\n",
       "      <td>0.944571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sports</td>\n",
       "      <td>2016-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Federer through to semis with efficient win ov...</td>\n",
       "      <td>0.826507</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sports</td>\n",
       "      <td>2016-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Serena beats Sharapova to reach semi fi</td>\n",
       "      <td>0.941752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sports</td>\n",
       "      <td>2016-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Rabada at the double as South Africa scent vic...</td>\n",
       "      <td>0.887556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sports</td>\n",
       "      <td>2016-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Keys falls to Zhang Shuai at Australian O</td>\n",
       "      <td>0.944163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sports</td>\n",
       "      <td>2016-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Rabada grabs six as England falter</td>\n",
       "      <td>0.732259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sports</td>\n",
       "      <td>2016-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Hales falls cheaply in Englands reply</td>\n",
       "      <td>0.871302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sports</td>\n",
       "      <td>2016-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>pol prices expected to rise in november</td>\n",
       "      <td>0.940285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>business</td>\n",
       "      <td>2015-10-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             headline  \\\n",
       "5               Kiwis beat Pakistan to bag series 2 0   \n",
       "9        Watson to lead Australia for final India T20   \n",
       "10            NZ Cricket apologises to Amir for a tau   \n",
       "2   Federer through to semis with efficient win ov...   \n",
       "7             Serena beats Sharapova to reach semi fi   \n",
       "4   Rabada at the double as South Africa scent vic...   \n",
       "8           Keys falls to Zhang Shuai at Australian O   \n",
       "1                  Rabada grabs six as England falter   \n",
       "3               Hales falls cheaply in Englands reply   \n",
       "6             pol prices expected to rise in november   \n",
       "\n",
       "    Cosine Distance with the queried article  Category based Cosine Distance  \\\n",
       "5                                   0.933562                             1.0   \n",
       "9                                   0.944474                             1.0   \n",
       "10                                  0.944571                             1.0   \n",
       "2                                   0.826507                             1.0   \n",
       "7                                   0.941752                             1.0   \n",
       "4                                   0.887556                             1.0   \n",
       "8                                   0.944163                             1.0   \n",
       "1                                   0.732259                             1.0   \n",
       "3                                   0.871302                             1.0   \n",
       "6                                   0.940285                             0.0   \n",
       "\n",
       "    Categoty       Date  \n",
       "5     sports 2016-01-31  \n",
       "9     sports 2016-01-30  \n",
       "10    sports 2016-01-27  \n",
       "2     sports 2016-01-26  \n",
       "7     sports 2016-01-26  \n",
       "4     sports 2016-01-25  \n",
       "8     sports 2016-01-25  \n",
       "1     sports 2016-01-24  \n",
       "3     sports 2016-01-23  \n",
       "6   business 2015-10-19  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf_based_model(row_index, num_similar_items):\n",
    "    couple_dist = cosine_distances(tfidf_headline_features,tfidf_headline_features[row_index])\n",
    "    category_dist = cosine_similarity(category_onehot_encoded, category_onehot_encoded[row_index])\n",
    "    indices = np.argsort(couple_dist.ravel())[0:num_similar_items]\n",
    "    df = pd.DataFrame({\n",
    "               'headline':news_df['Heading'][indices].values,\n",
    "                'Cosine Distance with the queried article': couple_dist[indices].ravel(),\n",
    "                'Category based Cosine Distance': category_dist[indices].ravel(), \n",
    "                'Categoty': news_df['NewsType'][indices].values,\n",
    "                'Date': news_df['Date'][indices].values}).sort_values('Category',ascending=False)\n",
    "\n",
    "    print(\"=\"*30,\"Queried article details\",\"=\"*30)\n",
    "    print('headline : ',user_df['Heading'][indices[6]])\n",
    "    print('Category : ', user_df['NewsType'][indices[6]])\n",
    "    print('Day and month : ', user_df['Date'][indices[6]])\n",
    "    print(\"\\n\",\"=\"*25,\"Recommended articles : \",\"=\"*23)\n",
    "    \n",
    "    #return df.iloc[1:,1]\n",
    "    return df.iloc[1:,].sort_values('Date',ascending=False)\n",
    "tfidf_based_model(56,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
